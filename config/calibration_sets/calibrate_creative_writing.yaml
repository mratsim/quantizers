calibration_set:
  max_seq_length: 8192
  shuffle: true
  seed: 42
  datasets:
    - dataset: "neuralmagic/calibration"
      subset: "LLM"
      columns: ["messages"]
      formatter: "chat_completion"
      num_samples: 256
    - dataset: "HuggingFaceH4/ultrachat_200k"
      columns: ["messages"]
      split: "train_sft"
      formatter: "chat_completion"
      num_samples: 256
    - dataset: "nvidia/OpenCodeInstruct"
      columns: ["input", "output"]
      formatter: "prompt_answer"
      split: "train"
      num_samples: 16
    - dataset: "CSJianYang/CodeArena"
      columns: ["messages"]
      formatter: "chat_completion"
      split: "test"
      num_samples: 32
    - dataset: "nvidia/OpenScienceReasoning-2"
      columns: ["input", "output"]
      formatter: "prompt_answer"
      split: "train"
      num_samples: 16
    - dataset: "MegaScience/MegaScience"
      columns: ["question", "answer"]
      formatter: "prompt_answer"
      split: "train"
      num_samples: 16
    - dataset: "Gryphe/Opus-WritingPrompts"
      columns: ["conversations"]
      formatter: "sharegpt"
      split: "train"
      num_samples: 32
    - dataset: "ServiceNow-AI/M2Lingual"
      subset: "full_data"
      columns: ["conversation"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 256
    - dataset: "anthracite-org/stheno-filtered-v1.1"
      columns: ["conversations"]
      formatter: "sharegpt"
      split: "train"
      num_samples: 32
    - dataset: "zerofata/Roleplay-Anime-Characters"
      columns: ["messages"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 16
    - dataset: "zerofata/Instruct-Anime"
      columns: ["messages"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 16
    - dataset: "zerofata/Instruct-Anime-CreativeWriting"
      columns: ["messages"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 16
    - dataset: "sam-paech/gutenberg3-generalfiction-scifi-fantasy-romance-adventure-dpo"
      columns: ["chosen"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 16
    - dataset: "nvidia/OpenMathInstruct-2"
      columns: ["problem", "generated_solution"]
      formatter: "prompt_answer"
      split: "train"
      num_samples: 16
    - dataset: "fka/awesome-chatgpt-prompts"
      columns: ["prompt"]
      formatter: "raw_text"
      split: "train"
      num_samples: 203
    - dataset: "databricks/databricks-dolly-15k"
      columns: ["instruction", "response"]
      formatter: "prompt_answer"
      split: "train"
      num_samples: 256
    - dataset: "FreedomIntelligence/SocraticChat"
      columns: ["conversations"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 32
    - dataset: "ruggsea/stanford-encyclopedia-of-philosophy_instruct"
      columns: ["question", "answer"]
      formatter: "prompt_answer"
      split: "train"
      num_samples: 32
    - dataset: "mlfoundations-dev/stackexchange_philosophy"
      columns: ["conversations"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 32
    - dataset: "theoldmandthesea/17k_business_book"
      columns: ["question", "answer"]
      formatter: "prompt_answer"
      split: "train"
      num_samples: 64
    - dataset: "anthracite-org/nopm_claude_writing_fixed"
      columns: ["conversations"]
      formatter: "chat_completion"
      split: "train"
      num_samples: 32
